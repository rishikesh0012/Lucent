#  Lucent

ocused intelligence from your documents

A local-first Document AI system that lets you upload PDFs and chat with them using Retrieval-Augmented Generation (RAG).

Private â€¢ Local â€¢ Explainable â€¢ Fast

## ğŸ“ Project Structure

```text
lucent/
â”œâ”€â”€ frontend/              # Next.js frontend (UI)
â”œâ”€â”€ backend/               # FastAPI backend (RAG pipeline)
â”œâ”€â”€ images/                # Screenshots & demo images
â””â”€â”€ README.md

frontend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx           # Main chat interface (Lucent UI)
â”‚   â”œâ”€â”€ layout.tsx         # Global layout & metadata
â”‚   â””â”€â”€ globals.css        # Global styles
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatInput.tsx      # Chat input field
â”‚   â”œâ”€â”€ Message.tsx        # Chat message renderer (Markdown + streaming)
â”‚   â”œâ”€â”€ UploadBox.tsx      # PDF upload component
â”‚   â””â”€â”€ PromptCards.tsx    # Suggested prompt cards
â”‚
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ api.ts             # Backend API calls (streaming support)
â”‚
â”œâ”€â”€ package.json           # Frontend dependencies
â””â”€â”€ tsconfig.json


backend/
â”œâ”€â”€ main.py                # FastAPI app & API routes
â”œâ”€â”€ rag.py                 # Retrieval-Augmented Generation logic
â”œâ”€â”€ ingest.py              # PDF ingestion & vector store creation
â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚
â”œâ”€â”€ docs/                  # Uploaded PDF files
â””â”€â”€ vectorstore/           # FAISS vector index storage

What is Lucent?

Lucent is a privacy-focused Document Question-Answering application that runs completely on your local machine.

Unlike cloud-based AI tools, Lucent:
	â€¢	Keeps your documents private
	â€¢	Uses Retrieval-Augmented Generation (RAG) to reduce hallucinations
	â€¢	Streams responses in real time
	â€¢	Answers questions using only your uploaded documents

Lucent is ideal for:
	â€¢	Research papers
	â€¢	Technical documentation
	â€¢	Resumes & reports
	â€¢	Learning modern RAG systems

â¸»

 Features
	â€¢	ğŸ“„ Upload PDF documents
	â€¢	ğŸ’¬ Chat with documents using natural language
	â€¢	ğŸ§  RAG pipeline with FAISS vector search
	â€¢	âš¡ Streaming responses (ChatGPT-style typing)
	â€¢	ğŸ§¾ Markdown & code block rendering
	â€¢	ğŸ¨ Clean, minimalist UI
	â€¢	ğŸ”’ Fully local â€” no cloud APIs

â¸»

How It Works (RAG Flow)

PDF Upload
   â†“
Text Extraction (PyPDF)
   â†“
Chunking + Embeddings (Ollama)
   â†“
FAISS Vector Store
   â†“
User Question
   â†“
Relevant Chunks Retrieved
   â†“
LLM Generates Grounded Answer (Streaming)


Lucent ensures responses are grounded in document content, not hallucinated.

â¸»

Tech Stack

Frontend
	â€¢	Next.js (App Router)
	â€¢	TypeScript
	â€¢	Tailwind CSS
	â€¢	React Markdown

Backend
	â€¢	FastAPI
	â€¢	LangChain
	â€¢	FAISS
	â€¢	Ollama (Mistral)

â¸»

âš™ï¸ Prerequisites

Install the following before running Lucent:
	â€¢	Node.js (v18+)
	â€¢	Python (3.10+ recommended)
	â€¢	Ollama

Install Ollama: https://ollama.com
Pull model - ollama pull mistral

Backend Setup
cd backend
pip install -r requirements.txt
uvicorn main:app --reload --port 8000
http://localhost:8000
http://localhost:8000/docs

Frontend Setup
cd frontend
npm install
npm run dev
http://localhost:3000

How to Use
	1.	Start Ollama
	2.	Run the backend
	3.	Run the frontend
	4.	Upload a PDF using the UI
	5.	Ask questions such as:
	â€¢	Summarize this document
	â€¢	Explain section 2
	â€¢	Provide examples mentioned in the PDF

Responses stream live as they are generated.

BY RISHIKESH K G